{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVfaLrjLvxvQ"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxtoY12mwmih"
   },
   "source": [
    "## Define the Following:\n",
    "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
    "\n",
    "### Input Layer:\n",
    "\n",
    "The input layer recieves the data. It is classified as 'visible' because it is the only layer that interacts directly with the input data. The input layer interacts with a subsequent hidden layer (if one exists). Input layers are typically represented with one cell for each feature/class of the input data, and weights applied to this layer directly effect only that feature.\n",
    "\n",
    "### Hidden Layer:\n",
    "\n",
    "A hidden layer is accessed through the input layer. They are 'inside' the network, and do not directly interact with the data.\n",
    "\n",
    "### Output Layer:\n",
    "\n",
    "The output layer returns values or whatever other information is needed for the application of the network. Generally, the output will be in the format of a vector or list of values. There will usually be a 'cell' or 'node' for each output class. If the network is used for a regression or classification problem with only one class, there will be one output node.\n",
    "\n",
    "### Neuron:\n",
    "\n",
    "An artificial neuron takes a group of inputs, multiplies them by their weights, adds the results and any bias and applies an activation function to determine the output. In some sense it is a decision function that takes multiple inputs and uses them to produce an output.\n",
    "In short, it uses a weighted sum of all inputs to determine the output.\n",
    "\n",
    "### Weight:\n",
    "\n",
    "A weight is how a given input should relate to an output. Positive or negative correlation, and how much a change in that input should change the output.\n",
    "\n",
    "### Activation Function:\n",
    "\n",
    "The activation function is the part of the artificial neuron that ~decides~ what the output of the neuron should be. In the case of using a sigmoid activation function, any extreme values will be pushed close to 1 or 0 and the output will be correspondingly \"on\" or \"off\", or if the input follows a normal distribution, the output should be close to linear. A linear activation function will make the output of the artificial neuron directly related to the input.\n",
    "\n",
    "### Node Map:\n",
    "\n",
    "A node map shows the structure of a whole neural network.\n",
    "\n",
    "### Perceptron:\n",
    "\n",
    "A perceptron is a neural network composed of a single neuron with all parameters directly exposed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXuy9WcWzxa4"
   },
   "source": [
    "## Inputs -> Outputs\n",
    "\n",
    "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlSwIJMC0A8F"
   },
   "source": [
    "#### Your Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sWR43PTwhSk"
   },
   "source": [
    "## Write your own perceptron code that can correctly classify a NAND gate. \n",
    "\n",
    "| x1 | x2 | y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sgh7VFGwnXGH"
   },
   "outputs": [],
   "source": [
    "nand_matrix = np.array([\n",
    "    [0,0,1],\n",
    "    [1,0,1],\n",
    "    [0,1,1],\n",
    "    [1,1,1],\n",
    "])\n",
    "\n",
    "ground_truth = [[1],[1],[1],[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return(1/(1 + np.exp(-x)))\n",
    "\n",
    "def sigmoid_ddx(x):\n",
    "    sx = sigmoid(x)\n",
    "    return(sx * (1-sx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01787578]\n",
      " [-1.02296743]]\n",
      "[[ 0.        ]\n",
      " [ 0.4766769 ]\n",
      " [-0.63560905]\n",
      " [-0.15893215]\n",
      " [-0.15893215]\n",
      " [-0.15893215]\n",
      " [-0.15893215]\n",
      " [-0.15893215]]\n",
      "[[0.5       ]\n",
      " [0.61696287]\n",
      " [0.34623979]\n",
      " [0.46035039]\n",
      " [0.46035039]\n",
      " [0.46035039]\n",
      " [0.46035039]\n",
      " [0.46035039]]\n"
     ]
    }
   ],
   "source": [
    "weights = (2 * np.random.random((2,1)) - 1)\n",
    "weighted_sum = np.dot(nand_matrix, weights)\n",
    "activated_output = sigmoid(weighted_sum)\n",
    "error = (ground_truth - activated_output)\n",
    "adjustments = error * sigmoid_ddx(activated_output)\n",
    "weights += np.dot(nand_matrix.T, adjustments)\n",
    "print(weights)\n",
    "print(weighted_sum)\n",
    "print(activated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06997848]\n",
      " [-0.0509341 ]]\n",
      "[[0.18242552]\n",
      " [0.17214154]\n",
      " [0.17498149]\n",
      " [0.16503245]\n",
      " [0.16503245]\n",
      " [0.16503245]\n",
      " [0.16503245]\n",
      " [0.16503245]]\n"
     ]
    }
   ],
   "source": [
    "weighted_sum = np.dot(nand_matrix, weights) - 1.5\n",
    "activated_output = sigmoid(weighted_sum)\n",
    "error = ground_truth - activated_output\n",
    "adjustments = error * sigmoid_ddx(activated_output)\n",
    "weights += np.dot(nand_matrix.T, adjustments)\n",
    "print(weights)\n",
    "print(activated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after training\n",
      "[[-0.06017196]\n",
      " [-0.06017196]]\n",
      "\n",
      "Output after training\n",
      "[[0.18242552]\n",
      " [0.17362197]\n",
      " [0.17362197]\n",
      " [0.16515744]\n",
      " [0.16515744]\n",
      " [0.16515744]\n",
      " [0.16515744]\n",
      " [0.16515744]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    weighted_sum = np.dot(nand_matrix, weights) - 1.5\n",
    "    \n",
    "    activated_output = sigmoid(weighted_sum)\n",
    "    \n",
    "    error = ground_truth - activated_output\n",
    "    \n",
    "    adjustments = error * sigmoid_ddx(activated_output)\n",
    "    \n",
    "    weights += np.dot(nand_matrix.T, adjustments)\n",
    "    \n",
    "print(\"Weights after training\")\n",
    "print(weights)\n",
    "\n",
    "print(\"\\nOutput after training\")\n",
    "print(activated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    \n",
    "    def __init__(self, rate = 0.1, itr = 10):\n",
    "        self.rate = rate\n",
    "        self.itr = itr\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        self.weight = np.zeros(1 + X.shape[1])\n",
    "        self.errors = []\n",
    "        for i in range(self.itr):\n",
    "            err = 0\n",
    "            for x_i, target in zip(X, y):\n",
    "                delta_w = self.rate * (target - self.predict(x_i))\n",
    "                self.weight[1:] += delta_w * x_i\n",
    "                self.weight[0] += delta_w\n",
    "                err += int(delta_w != 0.0)\n",
    "            self.errors.append(err)\n",
    "        return(self)\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.weight[1:]) + self.weight[0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return(np.where(self.net_input(X) >= 0.0, 1, -1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**Perceptron NAND gate**#\n",
    "\n",
    "def NAND_perceptron(x1, x2):\n",
    "    weights = np.array([-1, -1])\n",
    "    bias = 1.5\n",
    "    y = ((weights[0] * x1) + (weights[1] * x2) + bias)\n",
    "    #simulated activation function\n",
    "    if y <= 0 :\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [1], [1], [0], [0], [0], [0], [0]]\n",
      "[[1], [1], [1], [0], [0], [0], [0], [0]]\n"
     ]
    }
   ],
   "source": [
    "predict_nand = []\n",
    "for row in nand_matrix:\n",
    "    predict_nand.append([NAND_perceptron(row[0], row[1])])\n",
    "\n",
    "print(predict_nand)\n",
    "print(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Perceptron(0.5, 1000)\n",
    "p.fit(nand_matrix, ground_truth)\n",
    "p.predict(more_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pn = Perceptron(0.5, 100)\n",
    "pn.fit(nand_matrix, ground_truth)\n",
    "plt.plot(range(1, len(pn.errors) + 1), pn.errors, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of misclassifications')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf7sdqVs0s4x"
   },
   "source": [
    "## Implement your own Perceptron Class and use it to classify a binary dataset like: \n",
    "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
    "- [Titanic](https://raw.githubusercontent.com/ryanleeallred/datasets/master/titanic.csv)\n",
    "- [A two-class version of the Iris dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/Iris.csv)\n",
    "\n",
    "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W0tiX1F1hh2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 16)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "titanic = pd.read_csv('./titanic.csv')\n",
    "titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>222.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>667.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>890.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0    survived      pclass         age       sibsp       parch  \\\n",
       "count  891.000000  891.000000  891.000000  714.000000  891.000000  891.000000   \n",
       "mean   445.000000    0.383838    2.308642   29.699118    0.523008    0.381594   \n",
       "std    257.353842    0.486592    0.836071   14.526497    1.102743    0.806057   \n",
       "min      0.000000    0.000000    1.000000    0.420000    0.000000    0.000000   \n",
       "25%    222.500000    0.000000    2.000000   20.125000    0.000000    0.000000   \n",
       "50%    445.000000    0.000000    3.000000   28.000000    0.000000    0.000000   \n",
       "75%    667.500000    1.000000    3.000000   38.000000    1.000000    0.000000   \n",
       "max    890.000000    1.000000    3.000000   80.000000    8.000000    6.000000   \n",
       "\n",
       "             fare  \n",
       "count  891.000000  \n",
       "mean    32.204208  \n",
       "std     49.693429  \n",
       "min      0.000000  \n",
       "25%      7.910400  \n",
       "50%     14.454200  \n",
       "75%     31.000000  \n",
       "max    512.329200  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0       0\n",
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0       int64\n",
       "survived         int64\n",
       "pclass           int64\n",
       "sex             object\n",
       "age            float64\n",
       "sibsp            int64\n",
       "parch            int64\n",
       "fare           float64\n",
       "embarked        object\n",
       "class           object\n",
       "who             object\n",
       "adult_male        bool\n",
       "deck            object\n",
       "embark_town     object\n",
       "alive           object\n",
       "alone             bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  survived  pclass     sex   age  sibsp  parch     fare embarked  \\\n",
       "0           0         0       3    male  22.0      1      0   7.2500        S   \n",
       "1           1         1       1  female  38.0      1      0  71.2833        C   \n",
       "2           2         1       3  female  26.0      0      0   7.9250        S   \n",
       "3           3         1       1  female  35.0      1      0  53.1000        S   \n",
       "4           4         0       3    male  35.0      0      0   8.0500        S   \n",
       "\n",
       "   class    who  adult_male deck  embark_town alive  alone  \n",
       "0  Third    man        True  NaN  Southampton    no  False  \n",
       "1  First  woman       False    C    Cherbourg   yes  False  \n",
       "2  Third  woman       False  NaN  Southampton   yes   True  \n",
       "3  First  woman       False    C  Southampton   yes  False  \n",
       "4  Third    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in titanic_dropna.columns:\n",
    "    titanic_dropna[col] = titanic_dropna[col].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived    float64\n",
       "pclass      float64\n",
       "age         float64\n",
       "sibsp       float64\n",
       "parch       float64\n",
       "fare        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_dropna.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_dropna = titanic[['survived', 'pclass', 'age', 'sibsp', 'parch', 'fare']].dropna(axis=0)\n",
    "tiXtrain, tiXtest, tiytrain, tiytest = train_test_split(\n",
    "                titanic_dropna[\n",
    "                    ['pclass', 'age', 'sibsp', 'parch', 'fare']],\n",
    "                titanic_dropna['survived'],\n",
    "                test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((571, 5), (143, 5), (571,), (143,))"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiXtrain.shape, tiXtest.shape, tiytrain.shape, tiytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot cast array data from dtype('float64') to dtype('<U32') according to the rule 'safe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-259-1b783cf7021e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtiytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-247-75e2697b63bf>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mdelta_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdelta_w\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdelta_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-247-75e2697b63bf>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-247-75e2697b63bf>\u001b[0m in \u001b[0;36mnet_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnet_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot cast array data from dtype('float64') to dtype('<U32') according to the rule 'safe'"
     ]
    }
   ],
   "source": [
    "p = Perceptron(0.5, 1000)\n",
    "p.fit(tiXtrain, tiytrain)\n",
    "pred_t = p.predict(tiXtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QR4oAW1xdyu"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
    "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
    "- Try and implement your own backpropagation algorithm.\n",
    "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
